#!/usr/bin/env python3
"""
é’ˆç¸å¤§æˆå®ä½“æŠ½å–å™¨ - ç®€åŒ–ç‰ˆæœ¬
ä¸“æ³¨äºæ¢ç´¢å¤§æ¨¡å‹å®ä½“æŠ½å–æ•ˆæœï¼Œæ— å¤‡ç”¨æ–¹æ³•

ä½¿ç”¨æ–¹æ³•ï¼š
1. å®‰è£…ä¾èµ–ï¼špip install requests
2. è®¿é—®deepseekå®˜ç½‘ï¼Œæ³¨å†Œè´¦å·ï¼Œè·å–api key
3. è¿è¡Œç¨‹åºï¼špython zhenjiu_extractor.py

ç‰ˆæœ¬ï¼š4.0 (ç®€åŒ–ç‰ˆ) - DeepSeekç‰ˆæœ¬
"""

import os
import json
import re
import time
import sys
import requests
from pathlib import Path
from typing import List, Dict, Any

# å†…ç½®APIå¯†é’¥é…ç½®
DEEPSEEK_API_KEY = "sk-4b6506b9178d43fbb1319ab602d2c2da"  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„DeepSeek APIå¯†é’¥

# æ£€æŸ¥Pythonç‰ˆæœ¬
if sys.version_info < (3, 6):
    print("é”™è¯¯ï¼šéœ€è¦Python 3.6æˆ–æ›´é«˜ç‰ˆæœ¬")
    sys.exit(1)

# æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–
try:
    import requests
except ImportError:
    print("é”™è¯¯ï¼šç¼ºå°‘ä¾èµ–åŒ…ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š")
    print("   pip install requests")
    print("   æˆ–è€…ï¼špip install requests -i https://pypi.tuna.tsinghua.edu.cn/simple/")
    sys.exit(1)


class ZhenjiuDocumentSelector:
    """ã€Šé’ˆç¸å¤§æˆã€‹æ–‡æ¡£é€‰æ‹©å™¨"""
    
    def __init__(self, texts_dir="test_texts"):
        self.texts_dir = Path(texts_dir)
        self.documents = self.load_documents()
    
    def load_documents(self):
        """åŠ è½½æ‰€æœ‰æ–‡æ¡£"""
        if not self.texts_dir.exists():
            print(f"é”™è¯¯ï¼šæ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {self.texts_dir}")
            return []

        documents = []
        for file_path in sorted(self.texts_dir.glob("*.txt")):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()

                if content and len(content) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡ä»¶
                    documents.append({
                        'id': len(documents) + 1,
                        'filename': file_path.name,
                        'title': self.clean_title(file_path.stem),
                        'content': content,
                        'length': len(content),
                        'preview': content[:100] + "..." if len(content) > 100 else content
                    })
            except Exception as e:
                print(f"è­¦å‘Šï¼šè¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

        return documents
    
    def clean_title(self, filename):
        """æ¸…ç†æ ‡é¢˜"""
        # ç§»é™¤ç¼–å·å‰ç¼€
        title = re.sub(r'^\d+_', '', filename)
        title = title.replace('_', ' ')
        return title
    
    def display_documents(self):
        """æ˜¾ç¤ºæ–‡æ¡£åˆ—è¡¨"""
        if not self.documents:
            print("é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ–‡æ¡£")
            return

        print(f"\né’ˆç¸å¤§æˆç²¾é€‰æ–‡æ¡£åˆ—è¡¨ (å…±{len(self.documents)}ä¸ª)")
        print("=" * 60)
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        categories = {
            "åˆºæ³•ä¸“è®º": [],
            "æ­Œè¯€èµ‹æ–‡": [],
            "ç©´ä½ä¸»æ²»": [],
            "ç†è®ºåŸºç¡€": []
        }
        
        for doc in self.documents:
            category = self.get_category(doc['title'])
            categories[category].append(doc)
        
        for category, docs in categories.items():
            if docs:
                print(f"\n{category} ({len(docs)}ä¸ªæ–‡æ¡£)")
                print("-" * 40)
                for doc in docs:
                    print(f"  {doc['id']:2d}. {doc['title']:<25} ({doc['length']:4d}å­—ç¬¦)")
                    print(f"       é¢„è§ˆ: {doc['preview'][:60]}...")
    
    def get_category(self, title):
        """è·å–æ–‡æ¡£ç±»åˆ«"""
        if any(x in title for x in ['åˆºçƒ­è®º', 'åˆºç–Ÿè®º', 'åˆºå’³è®º', 'åˆºè…°ç—›è®º', 'ç¼ªåˆºè®º', 'å¥‡ç—…è®º', 'è°ƒç»è®º', 'éª¨ç©ºè®º']):
            return "åˆºæ³•ä¸“è®º"
        elif any(x in title for x in ['ç™¾ç—‡èµ‹', 'ç‰é¾™èµ‹', 'æ ‡å¹½èµ‹', 'å¸­å¼˜èµ‹', 'é‡‘é’ˆèµ‹', 'é€šç„æŒ‡è¦èµ‹', 'çµå…‰èµ‹', 'å…°æ±Ÿèµ‹', 'æµæ³¨æŒ‡å¾®èµ‹']):
            return "æ­Œè¯€èµ‹æ–‡"
        elif any(x in title for x in ['ç»ç©´ä¸»æ²»', 'æ‰‹å¤ªé˜´', 'æ‰‹å°‘é˜´', 'è¶³é˜³æ˜']):
            return "ç©´ä½ä¸»æ²»"
        else:
            return "ç†è®ºåŸºç¡€"
    
    def select_document(self):
        """é€‰æ‹©æ–‡æ¡£"""
        while True:
            try:
                choice = input(f"\nè¯·é€‰æ‹©æ–‡æ¡£ç¼–å· (1-{len(self.documents)}) æˆ–è¾“å…¥ 'q' é€€å‡º: ").strip()
                
                if choice.lower() == 'q':
                    return None
                
                doc_id = int(choice)
                if 1 <= doc_id <= len(self.documents):
                    selected_doc = self.documents[doc_id - 1]
                    print(f"\nå·²é€‰æ‹©: {selected_doc['title']}")
                    print(f"   æ–‡ä»¶: {selected_doc['filename']}")
                    print(f"   é•¿åº¦: {selected_doc['length']} å­—ç¬¦")
                    return selected_doc
                else:
                    print(f"é”™è¯¯ï¼šè¯·è¾“å…¥ 1-{len(self.documents)} ä¹‹é—´çš„æ•°å­—")

            except ValueError:
                print("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            except KeyboardInterrupt:
                print("\nç¨‹åºå·²é€€å‡º")
                return None


class ZhenjiuEntityExtractor:
    """ã€Šé’ˆç¸å¤§æˆã€‹å®ä½“æŠ½å–å™¨ - ç®€åŒ–ç‰ˆ"""

    def __init__(self, api_key: str = None):
        """åˆå§‹åŒ–æŠ½å–å™¨"""
        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„APIå¯†é’¥ï¼Œç„¶åä½¿ç”¨å†…ç½®å¯†é’¥ï¼Œæœ€åå°è¯•ç¯å¢ƒå˜é‡
        self.api_key = api_key or DEEPSEEK_API_KEY or os.getenv('DEEPSEEK_API_KEY')
        if not self.api_key:
            raise ValueError(
                "APIå¯†é’¥æœªé…ç½®ï¼è¯·æ£€æŸ¥ç¨‹åºå†…ç½®å¯†é’¥æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY"
            )

        # è®¾ç½®è¯·æ±‚å¤´
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        print("DeepSeekæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")

        # å…³ç³»æŠ½å–é…ç½®
        self.enable_relation_extraction = True
        self.relation_types = {
            'TREAT': 'æ²»ç–—å…³ç³»ï¼šæ²»æ³•æ²»ç–—ç—…å/ç—‡çŠ¶',
            'MANIFEST': 'è¡¨ç°å…³ç³»ï¼šç—…åè¡¨ç°ä¸ºç—‡çŠ¶',
            'MAIN_TREAT': 'ä¸»æ²»å…³ç³»ï¼šç©´ä½ä¸»æ²»ç—…å/ç—‡çŠ¶'
        }
    
    def build_optimized_prompt(self, text: str) -> str:
        """æ„å»ºä¼˜åŒ–çš„æç¤ºè¯"""
        
        prompt = f"""ä½ æ˜¯ã€Šé’ˆç¸å¤§æˆã€‹ä¸“å®¶ã€‚è¯·ä»å¤æ–‡ä¸­æŠ½å–å››ç±»å®ä½“ï¼Œè¦æ±‚å…¨é¢ä¸”å‡†ç¡®ã€‚è¯·ä»¥JSONæ ¼å¼è¾“å‡ºç»“æœã€‚

ã€å®ä½“ç±»å‹è¯¦ç»†å®šä¹‰ã€‘
1. ç—…åï¼šç–¾ç—…åç§°
   - æ ¼å¼ï¼šXçƒ­ç—…ã€Xç—…ã€Xç—‡ã€Xè¯ç­‰
   - ç¤ºä¾‹ï¼šè‚çƒ­ç—…ã€å¿ƒçƒ­ç—…ã€è„¾çƒ­ç—…ã€è‚ºçƒ­ç—…ã€è‚¾çƒ­ç—…ã€ç–Ÿç–¾ã€ç—¹ç—‡

2. ç—‡çŠ¶ï¼šç—‡çŠ¶è¡¨ç°ï¼ˆåŒ…æ‹¬å¤åˆç—‡çŠ¶ï¼‰
   - å•ä¸€ç—‡çŠ¶ï¼šè…¹ç—›ã€å¤´ç—›ã€èº«çƒ­ã€è…°ç—›ã€å–˜å’³ã€æ±—å‡º
   - å¤åˆç—‡çŠ¶ï¼šå°ä¾¿å…ˆé»„ã€èƒæ»¡ç—›ã€æ‰‹è¶³èºã€å’å¿ƒç—›ã€æ¶é£å¯’ã€èˆŒä¸Šé»„
   - çŠ¶æ€æè¿°ï¼šçƒ¦é—·ã€å–„å‘•ã€é¢èµ¤ã€æ— æ±—ã€å¤´é‡ã€é¢Šç—›ã€çƒ¦å¿ƒã€é¢œé’ã€æ¬²å‘•

3. ç©´ä½ï¼šç»ç»œç©´ä½
   - æ ¼å¼ï¼šè¶³/æ‰‹+ç»ç»œåã€å…·ä½“ç©´ä½å
   - ç¤ºä¾‹ï¼šè¶³å¥é˜´ã€æ‰‹å°‘é˜´ã€è¶³å¤ªé˜´ã€æ‰‹å¤ªé˜´ã€å°‘é˜³ã€å¤ªé˜³ã€é˜³æ˜ã€é£åºœã€ç™¾ä¼š

4. æ²»æ³•ï¼šæ²»ç–—æ–¹æ³•
   - ç¤ºä¾‹ï¼šåˆºã€å‡ºè¡€ã€è¡¥ã€æ³»ã€ç¸ã€é’ˆåˆºã€å¹³åˆºã€è‰¾ç¸

ã€å¤æ–‡åŸæ–‡ã€‘
{text}

ã€æŠ½å–è¦æ±‚ã€‘
- ä»”ç»†é˜…è¯»æ¯ä¸ªå¥å­ï¼Œä¸è¦é—æ¼ä»»ä½•ç—‡çŠ¶
- å¤åˆè¯æ±‡è¦å®Œæ•´æŠ½å–ï¼ˆå¦‚"å°ä¾¿å…ˆé»„"ä¸è¦æ‹†åˆ†ï¼‰
- æ¯ç§ç—…åå¯¹åº”çš„æ‰€æœ‰ç—‡çŠ¶éƒ½è¦æŠ½å–
- æ‰€æœ‰ç©´ä½å’Œæ²»æ³•éƒ½è¦è¯†åˆ«

ã€è¾“å‡ºè¦æ±‚ã€‘
å¿…é¡»è¾“å‡ºæ ‡å‡†JSONæ ¼å¼ï¼Œç»“æ„å¦‚ä¸‹ï¼š
{{
    "entities": [
        {{"text": "è‚çƒ­ç—…", "type": "ç—…å", "start_pos": 0, "end_pos": 3}},
        {{"text": "è…¹ç—›", "type": "ç—‡çŠ¶", "start_pos": 10, "end_pos": 12}}
    ]
}}"""

        return prompt
    
    def call_deepseek_api(self, prompt: str) -> str:
        """è°ƒç”¨DeepSeek API"""
        try:
            # DeepSeek APIç«¯ç‚¹ - ä½¿ç”¨å®Œæ•´çš„chat/completionsè·¯å¾„
            url = "https://api.deepseek.com/v1/chat/completions"
            data = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 4000,
                "temperature": 0.1,
                "top_p": 0.8,
                "response_format": {
                    "type": "json_object"
                }
            }

            response = requests.post(url, headers=self.headers, json=data)
            response.raise_for_status() # æ£€æŸ¥HTTPçŠ¶æ€ç 

            return response.json()['choices'][0]['message']['content']

        except requests.exceptions.RequestException as e:
            print(f"APIè¯·æ±‚é”™è¯¯è¯¦æƒ…: {e}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"å“åº”çŠ¶æ€ç : {e.response.status_code}")
                print(f"å“åº”å†…å®¹: {e.response.text}")
            raise Exception(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}")
        except Exception as e:
            raise Exception(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    def parse_response(self, response: str, original_text: str) -> List[Dict[str, Any]]:
        """è§£ææ¨¡å‹å“åº” - çº¯å¤§æ¨¡å‹æ–¹æ³•ï¼ŒAPIå¤±è´¥ç›´æ¥æŠ¥é”™"""
        entities = []
        
        try:
            # æ¸…ç†å“åº”
            cleaned = response.strip()
            
            # ç§»é™¤markdownæ ‡è®°
            if '```json' in cleaned:
                cleaned = cleaned.split('```json')[1].split('```')[0]
            elif '```' in cleaned:
                parts = cleaned.split('```')
                for part in parts:
                    if '{' in part and '}' in part:
                        cleaned = part
                        break
            
            cleaned = cleaned.strip()
            
            # ä¿®å¤å¸¸è§JSONé—®é¢˜
            cleaned = re.sub(r',\s*}', '}', cleaned)
            cleaned = re.sub(r',\s*]', ']', cleaned)
            
            # å¦‚æœJSONå¤ªé•¿ï¼Œæˆªå–å®Œæ•´éƒ¨åˆ†
            if len(cleaned) > 8000:
                # å¯»æ‰¾æœ€åä¸€ä¸ªå®Œæ•´çš„å®ä½“
                last_complete = cleaned.rfind('}, {')
                if last_complete > 0:
                    # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´å®ä½“çš„ç»“æŸä½ç½®
                    next_brace = cleaned.find('}', last_complete + 4)
                    if next_brace > 0:
                        cleaned = cleaned[:next_brace+1] + ']}'
                    else:
                        cleaned = cleaned[:last_complete] + '}]}'
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å®Œæ•´å®ä½“ï¼Œå°è¯•æ‰¾åˆ°æœ€åçš„}}
                    last_complete = cleaned.rfind('}}')
                    if last_complete > 0:
                        cleaned = cleaned[:last_complete+2] + ']}'
            
            # è§£æJSON
            try:
                data = json.loads(cleaned)
                raw_entities = data.get('entities', [])
            except json.JSONDecodeError as e:
                print(f"JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤: {str(e)}")
                # å°è¯•ä¿®å¤æˆªæ–­çš„JSON
                if 'Unterminated string' in str(e):
                    # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å®ä½“
                    pattern = r'\{"text":\s*"[^"]*",\s*"type":\s*"[^"]*"[^}]*\}'
                    matches = list(re.finditer(pattern, cleaned))
                    if matches:
                        last_match = matches[-1]
                        # æ„å»ºä¿®å¤çš„JSON
                        fixed_json = '{"entities": [' + cleaned[cleaned.find('{"text"'):last_match.end()] + ']}'
                        try:
                            data = json.loads(fixed_json)
                            raw_entities = data.get('entities', [])
                            print(f"JSONä¿®å¤æˆåŠŸï¼Œæå–åˆ° {len(raw_entities)} ä¸ªå®ä½“")
                        except:
                            print("JSONä¿®å¤å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                            raw_entities = []
                    else:
                        raw_entities = []
                else:
                    raise
            
            # éªŒè¯å’Œæ¸…ç†å®ä½“
            for entity in raw_entities:
                if self.validate_entity(entity, original_text):
                    # ç§»é™¤ç½®ä¿¡åº¦å­—æ®µ
                    clean_entity = {
                        'text': entity['text'],
                        'type': entity['type'],
                        'start_pos': entity.get('start_pos', -1),
                        'end_pos': entity.get('end_pos', -1)
                    }
                    entities.append(clean_entity)
            
            return entities
            
        except json.JSONDecodeError as e:
            print(f"é”™è¯¯ï¼šJSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response[:200]}...")
            return []
        except Exception as e:
            print(f"é”™è¯¯ï¼šå“åº”è§£æå¤±è´¥: {e}")
            return []
    
    def validate_entity(self, entity: Dict[str, Any], original_text: str) -> bool:
        """éªŒè¯å®ä½“"""
        required_fields = ['text', 'type']
        
        for field in required_fields:
            if field not in entity:
                return False
        
        text = entity['text']
        if not text or len(text) < 1:
            return False
        
        # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åœ¨åŸæ–‡ä¸­
        if text not in original_text:
            return False
        
        return True
    
    def extract_entities(self, text: str, doc_title: str = "") -> Dict[str, Any]:
        """æŠ½å–å®ä½“ä¸»å‡½æ•°"""
        print(f"å¼€å§‹åˆ†ææ–‡æ¡£: {doc_title}")
        print(f"   é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # æ„å»ºæç¤ºè¯
        prompt = self.build_optimized_prompt(text)

        # è¾“å‡ºpromptåˆ°ç»ˆç«¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from config import get_show_prompts
            if get_show_prompts():
                print(f"\n{'='*60}")
                print(f"ğŸ¤– DeepSeekæ¨¡å‹ - å®ä½“æŠ½å–Prompt")
                print(f"{'='*60}")
                print(prompt)
                print(f"{'='*60}\n")
        except ImportError:
            pass  # å¦‚æœæ²¡æœ‰configæ–‡ä»¶ï¼Œé»˜è®¤ä¸æ˜¾ç¤º

        # è°ƒç”¨API
        start_time = time.time()
        try:
            response = self.call_deepseek_api(prompt)
            processing_time = time.time() - start_time
            
            print(f"æ¨¡å‹å“åº”æ—¶é—´: {processing_time:.2f}ç§’")

            # è§£æå®ä½“
            entities = self.parse_response(response, text)

            return {
                'success': True,
                'entities': entities,
                'processing_time': processing_time,
                'text_length': len(text),
                'entity_count': len(entities),
                'doc_title': doc_title,
                'raw_response': response
            }

        except Exception as e:
            print(f"é”™è¯¯ï¼šæŠ½å–å¤±è´¥: {e}")
            return {
                'success': False,
                'entities': [],
                'processing_time': time.time() - start_time,
                'error': str(e),
                'doc_title': doc_title
            }

    def extract_relations(self, text: str, entities: List[Dict[str, Any]], doc_title: str = "") -> Dict[str, Any]:
        """åŸºäºå·²æŠ½å–çš„å®ä½“ï¼ŒæŠ½å–å…³ç³»"""
        if not entities or not self.enable_relation_extraction:
            return {
                'success': True,
                'relations': [],
                'processing_time': 0,
                'doc_title': doc_title
            }

        print(f"å¼€å§‹æŠ½å–å…³ç³»: {doc_title}")
        print(f"   åŸºäº {len(entities)} ä¸ªå®ä½“")

        # æ„å»ºå…³ç³»æŠ½å–æç¤ºè¯
        prompt = self.build_relation_prompt(text, entities)

        # è¾“å‡ºå…³ç³»æŠ½å–promptåˆ°ç»ˆç«¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from config import get_show_prompts
            if get_show_prompts():
                print(f"\n{'='*60}")
                print(f"ğŸ”— DeepSeekæ¨¡å‹ - å…³ç³»æŠ½å–Prompt")
                print(f"{'='*60}")
                print(prompt)
                print(f"{'='*60}\n")
        except ImportError:
            pass  # å¦‚æœæ²¡æœ‰configæ–‡ä»¶ï¼Œé»˜è®¤ä¸æ˜¾ç¤º

        # è°ƒç”¨API
        start_time = time.time()
        try:
            response = self.call_deepseek_api(prompt)
            processing_time = time.time() - start_time

            print(f"å…³ç³»æŠ½å–å“åº”æ—¶é—´: {processing_time:.2f}ç§’")

            # è§£æå…³ç³»
            relations = self.parse_relation_response(response, entities)

            return {
                'success': True,
                'relations': relations,
                'processing_time': processing_time,
                'relation_count': len(relations),
                'doc_title': doc_title,
                'raw_response': response
            }

        except Exception as e:
            print(f"é”™è¯¯ï¼šå…³ç³»æŠ½å–å¤±è´¥: {e}")
            return {
                'success': False,
                'relations': [],
                'processing_time': time.time() - start_time,
                'error': str(e),
                'doc_title': doc_title
            }

    def build_relation_prompt(self, text: str, entities: List[Dict[str, Any]]) -> str:
        """æ„å»ºå…³ç³»æŠ½å–æç¤ºè¯"""

        # æ ¼å¼åŒ–å®ä½“ä¿¡æ¯
        entity_info = []
        for i, entity in enumerate(entities):
            entity_info.append(f"{i+1}. {entity['text']} ({entity['type']})")

        entities_str = "\n".join(entity_info)

        prompt = f"""ä½ æ˜¯ä¸­åŒ»æ–‡çŒ®åˆ†æä¸“å®¶ã€‚è¯·åŸºäºå·²è¯†åˆ«çš„å®ä½“ï¼ŒæŠ½å–å®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚

æ–‡æœ¬ï¼š{text}

å·²è¯†åˆ«å®ä½“ï¼š
{entities_str}

è¯·è¯†åˆ«ä»¥ä¸‹ç±»å‹çš„å…³ç³»ï¼š
1. TREATï¼ˆæ²»ç–—ï¼‰ï¼šæ²»æ³•æ²»ç–—ç—…å/ç—‡çŠ¶
2. MANIFESTï¼ˆè¡¨ç°ï¼‰ï¼šç—…åè¡¨ç°ä¸ºç—‡çŠ¶
3. MAIN_TREATï¼ˆä¸»æ²»ï¼‰ï¼šç©´ä½ä¸»æ²»ç—…å/ç—‡çŠ¶

è¦æ±‚ï¼š
- åªæŠ½å–æ˜ç¡®çš„å…³ç³»ï¼Œä¸è¦æ¨æµ‹
- å…³ç³»å¿…é¡»åœ¨æ–‡æœ¬ä¸­æœ‰æ˜ç¡®ä½“ç°
- å®ä½“å¿…é¡»æ¥è‡ªä¸Šè¿°å·²è¯†åˆ«å®ä½“åˆ—è¡¨

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "relations": [
    {{
      "head": "å®ä½“1æ–‡æœ¬",
      "head_type": "å®ä½“1ç±»å‹",
      "relation": "å…³ç³»ç±»å‹",
      "tail": "å®ä½“2æ–‡æœ¬",
      "tail_type": "å®ä½“2ç±»å‹",
      "confidence": 0.9
    }}
  ]
}}"""

        return prompt

    def parse_relation_response(self, response: str, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è§£æå…³ç³»æŠ½å–å“åº”"""
        relations = []

        try:
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if not json_match:
                return relations

            json_str = json_match.group()
            data = json.loads(json_str)

            # åˆ›å»ºå®ä½“æ–‡æœ¬åˆ°å®ä½“çš„æ˜ å°„
            entity_map = {entity['text']: entity for entity in entities}

            # è§£æå…³ç³»
            for rel_data in data.get('relations', []):
                head_text = rel_data.get('head', '').strip()
                tail_text = rel_data.get('tail', '').strip()
                relation_type = rel_data.get('relation', '').strip()

                # éªŒè¯å®ä½“å­˜åœ¨å’Œå…³ç³»ç±»å‹
                if (head_text in entity_map and tail_text in entity_map and
                    relation_type in self.relation_types):

                    relation = {
                        'head': head_text,
                        'head_type': rel_data.get('head_type', entity_map[head_text]['type']),
                        'relation': relation_type,
                        'tail': tail_text,
                        'tail_type': rel_data.get('tail_type', entity_map[tail_text]['type']),
                        'confidence': rel_data.get('confidence', 0.8)
                    }

                    relations.append(relation)

        except Exception as e:
            print(f"å…³ç³»è§£æé”™è¯¯: {e}")

        return relations

    def extract_entities_and_relations(self, text: str, doc_title: str = "") -> Dict[str, Any]:
        """ç»¼åˆæŠ½å–å®ä½“å’Œå…³ç³»"""
        print(f"ğŸš€ å¼€å§‹ç»¼åˆæŠ½å–: {doc_title}")

        # ç¬¬ä¸€æ­¥ï¼šæŠ½å–å®ä½“
        entity_result = self.extract_entities(text, doc_title)

        if not entity_result['success']:
            return {
                'success': False,
                'entities': [],
                'relations': [],
                'error': entity_result.get('error', 'å®ä½“æŠ½å–å¤±è´¥'),
                'doc_title': doc_title
            }

        entities = entity_result['entities']

        # ç¬¬äºŒæ­¥ï¼šåŸºäºå®ä½“æŠ½å–å…³ç³»
        relation_result = self.extract_relations(text, entities, doc_title)

        # åˆå¹¶ç»“æœ
        return {
            'success': True,
            'entities': entities,
            'relations': relation_result['relations'],
            'entity_count': len(entities),
            'relation_count': len(relation_result['relations']),
            'processing_time': entity_result['processing_time'] + relation_result['processing_time'],
            'doc_title': doc_title,
            'entity_result': entity_result,
            'relation_result': relation_result
        }

    def display_results(self, text: str, result: Dict[str, Any]):
        """æ˜¾ç¤ºæŠ½å–ç»“æœ"""
        print(f"\n" + "="*60)
        print(f"é’ˆç¸å¤§æˆå®ä½“æŠ½å–ç»“æœ")
        print(f"="*60)

        print(f"\næ–‡æ¡£: {result.get('doc_title', 'æœªçŸ¥')}")
        print(f"æ–‡æœ¬ä¿¡æ¯:")
        print(f"   é•¿åº¦: {len(text)} å­—ç¬¦")
        print(f"   å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f}ç§’")

        if not result['success']:
            print(f"\né”™è¯¯ï¼šæŠ½å–å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return
        
        entities = result['entities']
        print(f"   æŠ½å–å®ä½“æ•°: {len(entities)} ä¸ª")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        type_stats = {}
        for entity in entities:
            entity_type = entity['type']
            if entity_type not in type_stats:
                type_stats[entity_type] = []
            type_stats[entity_type].append(entity)
        
        print(f"\næŠ½å–ç»“æœ:")

        for entity_type in ['ç—…å', 'ç—‡çŠ¶', 'ç©´ä½', 'æ²»æ³•']:
            entities_of_type = type_stats.get(entity_type, [])
            unique_texts = sorted(set([e['text'] for e in entities_of_type]))

            print(f"\n   {entity_type} ({len(unique_texts)}ä¸ª):")
            if unique_texts:
                for i, entity_text in enumerate(unique_texts, 1):
                    print(f"      {i:2d}. {entity_text}")
            else:
                print(f"      (æ— )")


def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print("æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")

    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
    print(f"   Pythonç‰ˆæœ¬: {python_version}")

    # æ£€æŸ¥ä¾èµ–åŒ…
    try:
        import requests
        print(f"   requestsåŒ…: å·²å®‰è£…")
    except ImportError:
        print(f"   requestsåŒ…: æœªå®‰è£…")
        return False
    
    # æ£€æŸ¥APIå¯†é’¥
    if DEEPSEEK_API_KEY:
        print(f"   APIå¯†é’¥: å·²å†…ç½®")
    else:
        api_key = os.getenv('DEEPSEEK_API_KEY')
        if api_key:
            print(f"   APIå¯†é’¥: ç¯å¢ƒå˜é‡å·²è®¾ç½®")
        else:
            print(f"   APIå¯†é’¥: æœªé…ç½®")
            return False

    # æ£€æŸ¥æ–‡æ¡£ç›®å½•
    texts_dir = Path("test_texts")
    if texts_dir.exists():
        file_count = len(list(texts_dir.glob("*.txt")))
        print(f"   æ–‡æ¡£ç›®å½•: å·²å­˜åœ¨ ({file_count}ä¸ªæ–‡ä»¶)")
    else:
        print(f"   æ–‡æ¡£ç›®å½•: ä¸å­˜åœ¨")
        return False

    print("ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("é’ˆç¸å¤§æˆå®ä½“æŠ½å–å™¨ - ç®€åŒ–ç‰ˆæœ¬")
    print("="*50)
    print("åŠŸèƒ½ï¼šæ¢ç´¢å¤§æ¨¡å‹å®ä½“æŠ½å–æ•ˆæœï¼Œçº¯å¤§æ¨¡å‹æ–¹æ³•ï¼Œæ— å¤‡ç”¨æœºåˆ¶")
    print("æ¨¡å‹ï¼šDeepSeek (deepseek-chat)")
    print("ç‰ˆæœ¬ï¼š4.0 (ç®€åŒ–ç‰ˆ)")
    print("="*50)

    # æ£€æŸ¥è¿è¡Œç¯å¢ƒ
    if not check_environment():
        print("\né”™è¯¯ï¼šç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®ï¼š")
        print("1. å®‰è£…ä¾èµ–åŒ…ï¼š")
        print("   pip install requests")
        print("   æˆ–ä½¿ç”¨å›½å†…é•œåƒï¼špip install requests -i https://pypi.tuna.tsinghua.edu.cn/simple/")
        print("2. ç¡®ä¿test_textsæ–‡ä»¶å¤¹å­˜åœ¨ä¸”åŒ…å«æ–‡æ¡£")
        print("æ³¨æ„ï¼šAPIå¯†é’¥å·²å†…ç½®ï¼Œæ— éœ€é¢å¤–é…ç½®")
        return
    
    try:
        # åˆå§‹åŒ–æ–‡æ¡£é€‰æ‹©å™¨
        selector = ZhenjiuDocumentSelector()
        
        # æ˜¾ç¤ºæ–‡æ¡£åˆ—è¡¨
        selector.display_documents()
        
        # é€‰æ‹©æ–‡æ¡£
        selected_doc = selector.select_document()
        if not selected_doc:
            print("ç¨‹åºå·²é€€å‡º")
            return
        
        # åˆå§‹åŒ–æŠ½å–å™¨
        extractor = ZhenjiuEntityExtractor()
        
        # è¿›è¡Œå®ä½“æŠ½å–
        result = extractor.extract_entities(selected_doc['content'], selected_doc['title'])
        
        # æ˜¾ç¤ºç»“æœ
        extractor.display_results(selected_doc['content'], result)
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_file = f"extraction_result_{selected_doc['filename'][:-4]}.json"
        output_data = {
            "source_document": selected_doc,
            "extraction_result": result,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")

        # æ€§èƒ½æ€»ç»“
        if result['success']:
            entity_count = result['entity_count']
            processing_time = result['processing_time']
            print(f"\næ€§èƒ½æ€»ç»“:")
            print(f"   æˆåŠŸæŠ½å– {entity_count} ä¸ªå®ä½“")
            print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")

        print(f"\nç¨‹åºè¿è¡Œå®Œæˆ")
        
    except Exception as e:
        print(f"é”™è¯¯ï¼šç¨‹åºè¿è¡Œå¤±è´¥: {e}")
        print(f"è¯·æ£€æŸ¥:")
        print(f"   1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print(f"   2. æ˜¯å¦æœ‰è¶³å¤Ÿçš„APIä½™é¢")
        print(f"   3. APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆï¼ˆå·²å†…ç½®ï¼‰")


if __name__ == "__main__":
    main()
